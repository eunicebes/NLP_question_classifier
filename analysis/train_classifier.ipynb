{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train Classifier with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import jieba\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## type dict\n",
    "Grammar = {'完成式': 1, '進行式': 2, '過去式': 3, '未來式': 4, '關係代名詞': 5, '不定詞': 6, '名詞子句': 7, \n",
    "           '被動': 8, '介係詞': 9, '連接詞': 10, '假設語氣': 11, '分詞': 12, 'PT': 13, '其它': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Grammar = {'1': '完成式', '2': '進行式', '3': '過去式', '4': '未來式', '5': '關係代名詞', '6': '不定詞', '7': '名詞子句', '8': '被動', '9': '介係詞', \\\n",
    "           '10': '連接詞', '11': '假設語氣', '12': '分詞', '13': 'PT', '0': '其它'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('questions_nondup_dup.csv') as csvfile:\n",
    "    data_dict = defaultdict()\n",
    "    for row in csv.DictReader(csvfile):\n",
    "        data_dict[row['question_id']] = row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class DataHelper(object):\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.stopwords = ['什麼', '請問', '這裡', '不是', '意思', '這邊', '謝謝', '這句', '為何', '使用', '怎麼', '要加', '老師', '還是', '如何', '甚麼', '一下', '這個', '這樣', '問為', '因為', '何要', '用過', '是不是', '一個', '應該', '直接', '好像', '如果', '何不', '兩個', '這是', '何用', '需要', '時候', '所以', '您好', '起來', '還有', '加上', '寫成', '你好', '此句', '有點', '問此', '不好意思', '不到', '像是', '這裏', '為什麼']\n",
    "        \n",
    "        with open('{0}'.format(self.file)) as data_file:\n",
    "            self.unamb_data = defaultdict(list)\n",
    "            self.amb_data = defaultdict(list)\n",
    "            for row in csv.DictReader(data_file):\n",
    "                if row['ambiguous'] == '0':\n",
    "                    # can't directly use row.values() as it doesn't grantee the order\n",
    "                    self.unamb_data[row['type']].append([row['question_id'], row['member_id'], \\\n",
    "                                                         row['type'], row['question'], row['ambiguous']])\n",
    "                else:\n",
    "                    self.amb_data[row['type']].append([row['question_id'], row['member_id'], \\\n",
    "                                                         row['type'], row['question'], row['ambiguous']])\n",
    "                    \n",
    "    def get_type_dist(self, outfile):\n",
    "        type_counter = Counter()\n",
    "        for key, vals in self.unamb_data.items():\n",
    "            type_counter[key] += len(vals)\n",
    "          \n",
    "        print('Unambiguous data:')\n",
    "        pprint.pprint(type_counter)\n",
    "        \n",
    "        type_counter = Counter()\n",
    "        for key, vals in self.amb_data.items():\n",
    "            type_counter[key] += len(vals)\n",
    "            \n",
    "        print('Ambiguous data:')\n",
    "        pprint.pprint(type_counter)\n",
    "            \n",
    "#         header = list(Grammar.values())\n",
    "#         with open(outfile, 'w') as csvfile:\n",
    "#             spamwriter = csv.writer(csvfile, delimiter = ',', quotechar = '\"')\n",
    "#             for key, val in type_counter.items():\n",
    "#                 spamwriter.writerow([header[header.index(Grammar[key])], val])\n",
    "        \n",
    "        \n",
    "    def get_shuffled_data(self, ratio = 8):\n",
    "        X_train = []\n",
    "        X_test = []\n",
    "        Y_train = []\n",
    "        Y_test = []\n",
    "        member_train = []\n",
    "        member_test = []\n",
    "        question_train = []\n",
    "        question_test = []\n",
    "        for key, record in self.unamb_data.items():\n",
    "            if key == '13':\n",
    "                continue\n",
    "            questions = list(list(zip(*record))[3]) # get question list from records\n",
    "            members = list(list(zip(*record))[1]) # get memberid list from records\n",
    "            question_idx = list(list(zip(*record))[0])\n",
    "            random.shuffle(questions)\n",
    "            split_point = len(questions)*ratio//10\n",
    "            train = questions[:split_point]\n",
    "            test = questions[split_point:]\n",
    "            member_train += members[:split_point]\n",
    "            member_test += members[split_point:]\n",
    "            question_train += question_idx[:split_point]\n",
    "            question_test += question_idx[split_point:]\n",
    "            X_train += train\n",
    "            X_test += test\n",
    "            Y_train += [key]*len(train) # repeat len(train) times\n",
    "            Y_test += [key]*len(test)\n",
    "            \n",
    "        X_train_text = self.cut_questions(X_train)\n",
    "        X_test_text = self.cut_questions(X_test)\n",
    "        return X_train_text, np.array(Y_train), X_test_text, np.array(Y_test), member_train, member_test, question_train, question_test\n",
    "    \n",
    "    # use non-duplications as training and duplications as testing\n",
    "    # the file should be questions_nondup_dup.csv\n",
    "    def get_fixed_data(self):\n",
    "        X_train = []\n",
    "        X_test = []\n",
    "        Y_train = []\n",
    "        Y_test = []\n",
    "        member_train = []\n",
    "        member_test = []\n",
    "        question_train = []\n",
    "        question_test = []\n",
    "        \n",
    "        for key, record in self.unamb_data.items():\n",
    "            if key == '13':\n",
    "                continue\n",
    "            questions = list(list(zip(*record))[3]) # get question list from records\n",
    "            members = list(list(zip(*record))[1]) # get memberid list from records\n",
    "            question_idx = list(list(zip(*record))[0])\n",
    "            X_train += questions\n",
    "            Y_train += [key]*len(questions)\n",
    "            member_train += members\n",
    "            question_train += question_idx\n",
    "        for key, record in self.amb_data.items():\n",
    "            if key == '13':\n",
    "                continue\n",
    "            questions = list(list(zip(*record))[3]) # get question list from records\n",
    "            members = list(list(zip(*record))[1]) # get memberid list from records\n",
    "            question_idx = list(list(zip(*record))[0])\n",
    "            X_test += questions\n",
    "            Y_test += [key]*len(questions)\n",
    "            member_test += members\n",
    "            question_test += question_idx\n",
    "            \n",
    "        X_train_text = self.cut_questions(X_train)\n",
    "        X_test_text = self.cut_questions(X_test)\n",
    "        return X_train_text, np.array(Y_train), X_test_text, np.array(Y_test), member_train, member_test, question_train, question_test\n",
    "        \n",
    "    def cut_questions(self, data):\n",
    "        corpus = []\n",
    "        for q in data:\n",
    "            segs = jieba.cut(q, cut_all=False)\n",
    "            final = [seg for seg in segs if seg not in self.stopwords]\n",
    "            corpus.append(' '.join(final))\n",
    "        return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dh = DataHelper('questions_nondup_dup2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unambiguous data:\n",
      "Counter({'13': 2869,\n",
      "         '9': 1000,\n",
      "         '10': 528,\n",
      "         '12': 515,\n",
      "         '5': 462,\n",
      "         '3': 448,\n",
      "         '8': 244,\n",
      "         '1': 207,\n",
      "         '2': 193,\n",
      "         '6': 96,\n",
      "         '7': 88,\n",
      "         '11': 57,\n",
      "         '4': 35,\n",
      "         '0': 2})\n",
      "Ambiguous data:\n",
      "Counter({'5': 491,\n",
      "         '1': 410,\n",
      "         '2': 309,\n",
      "         '8': 306,\n",
      "         '3': 156,\n",
      "         '6': 115,\n",
      "         '9': 91,\n",
      "         '7': 36,\n",
      "         '10': 20,\n",
      "         '11': 15})\n"
     ]
    }
   ],
   "source": [
    "dh.get_type_dist('question_type_dist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### get shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (3875, 10760)\n",
      "y train shape: (3095,)\n"
     ]
    }
   ],
   "source": [
    "X_train_text, y_train, X_test_text, y_test, member_train, member_test, question_train, question_test = dh.get_shuffled_data()\n",
    "print('X train shape: {}'.format(X_train.shape))\n",
    "print('y train shape: {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## extract features of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TextFeature(object):\n",
    "    def __init__(self, training_data, testing_data):\n",
    "        self.training_text = training_data\n",
    "        self.testing_text = testing_data\n",
    "        \n",
    "    def get_tfidf(self, use_idf = True):\n",
    "#         texts = self.training_text + self.testing_text\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(use_idf = True)\n",
    "        self.tfidf_vectorizer.fit(self.training_text)\n",
    "        X_train = self.tfidf_vectorizer.transform(self.training_text)\n",
    "        X_test = None\n",
    "        if self.testing_text != None:\n",
    "            X_test = self.tfidf_vectorizer.transform(self.testing_text)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    def dump_vectorizer(self, outfile):\n",
    "        joblib.dump(self.tfidf_vectorizer, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3095, 9621)\n",
      "(780, 9621)\n"
     ]
    }
   ],
   "source": [
    "tf = TextFeature(X_train_text, X_test_text)\n",
    "X_train, X_test = tf.get_tfidf()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Corss Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Get all data and get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train_text, y_train, X_test_text, y_test, member_train, member_test, question_train, question_test = dh.get_fixed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf = TextFeature(X_train_text, X_test_text)\n",
    "X_train, X_test = tf.get_tfidf()\n",
    "\n",
    "# dump tfidf vectorizer\n",
    "# tf.dump_vectorizer('tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Naive Bayes corss validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "NB_cv = Pipeline([('cls', MultinomialNB()),])\n",
    "parameters = {'cls__alpha': (0.5, 0.8, 1.0, 5, 10)}\n",
    "gs_cls = GridSearchCV(NB_cv, param_grid = parameters, cv = 10, n_jobs = mp.cpu_count()-1)\n",
    "gs_cls = gs_cls.fit(X_train.todense(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paras: {'cls__alpha': 0.5}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       1.00      0.83      0.90       207\n",
      "         10       0.89      0.92      0.91       528\n",
      "         11       0.92      0.19      0.32        57\n",
      "         12       0.91      0.94      0.93       515\n",
      "          2       0.96      0.80      0.87       193\n",
      "          3       0.92      0.85      0.88       448\n",
      "          4       0.00      0.00      0.00        35\n",
      "          5       0.92      0.94      0.93       462\n",
      "          6       1.00      0.09      0.17        96\n",
      "          7       1.00      0.11      0.20        88\n",
      "          8       0.98      0.50      0.66       244\n",
      "          9       0.70      0.99      0.82      1000\n",
      "\n",
      "avg / total       0.86      0.84      0.82      3875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Best Paras:', gs_cls.best_params_)\n",
    "y_predict = gs_cls.predict(X_train)\n",
    "y_predict_prob = gs_cls.predict_proba(X_train)\n",
    "infile = 'predicted/NB_unamb_predict.csv'\n",
    "cat = [Grammar[item] for item in gs_cls.best_estimator_.classes_]\n",
    "with open(infile, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter = ',', quotechar = '\"')\n",
    "    spamwriter.writerow(['question_id', 'member_id', 'question'] + cat)\n",
    "    for i in range(len(question_train)):\n",
    "        writestring = [question_train[i], data_dict[question_train[i]]['member_id'], data_dict[question_train[i]]['question']]\n",
    "        writestring += list(y_predict_prob[i])\n",
    "        spamwriter.writerow(writestring)\n",
    "        \n",
    "print(metrics.classification_report(y_train, y_predict))\n",
    "\n",
    "y_predict_prob = gs_cls.predict_proba(X_test)\n",
    "infile = 'predicted/NB_amb_predict.csv'\n",
    "with open(infile, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter = ',', quotechar = '\"')\n",
    "    spamwriter.writerow(['question_id', 'member_id', 'question'] + cat)\n",
    "    for i in range(len(question_test)):\n",
    "        writestring = [question_test[i], data_dict[question_test[i]]['member_id'], data_dict[question_test[i]]['question']]\n",
    "        writestring += list(y_predict_prob[i])\n",
    "        spamwriter.writerow(writestring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Random Forest cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "RF_cv = Pipeline([('cls', RandomForestClassifier()),])\n",
    "parameters = {'cls__n_estimators': (20, 64, 128, 256),\n",
    "              'cls__max_features': ['auto', 'sqrt', 'log2']}\n",
    "gs_cls = GridSearchCV(RF_cv, param_grid = parameters, cv = 10, n_jobs = mp.cpu_count()-1)\n",
    "gs_cls = gs_cls.fit(X_train.todense(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paras: {'cls__n_estimators': 128, 'cls__max_features': 'sqrt'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         2\n",
      "          1       1.00      1.00      1.00       207\n",
      "         10       1.00      1.00      1.00       528\n",
      "         11       1.00      1.00      1.00        57\n",
      "         12       1.00      1.00      1.00       515\n",
      "          2       1.00      1.00      1.00       193\n",
      "          3       1.00      1.00      1.00       448\n",
      "          4       1.00      1.00      1.00        35\n",
      "          5       1.00      1.00      1.00       462\n",
      "          6       1.00      1.00      1.00        96\n",
      "          7       1.00      1.00      1.00        88\n",
      "          8       1.00      1.00      1.00       244\n",
      "          9       1.00      1.00      1.00      1000\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Best Paras:', gs_cls.best_params_)\n",
    "y_predict = gs_cls.predict(X_train)\n",
    "y_predict_prob = gs_cls.predict_proba(X_train)\n",
    "\n",
    "infile = 'predicted/RF_unamb_predict.csv'\n",
    "with open(infile, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter = ',', quotechar = '\"')\n",
    "    spamwriter.writerow(['question_id', 'member_id', 'question'] + cat)\n",
    "    for i in range(len(question_train)):\n",
    "        writestring = [question_train[i], data_dict[question_train[i]]['member_id'], data_dict[question_train[i]]['question']]\n",
    "        writestring += list(y_predict_prob[i])\n",
    "        spamwriter.writerow(writestring)\n",
    "        \n",
    "print(metrics.classification_report(y_train, y_predict))\n",
    "\n",
    "y_predict_prob = gs_cls.predict_proba(X_test)\n",
    "infile = 'predicted/RF_amb_predict.csv'\n",
    "with open(infile, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter = ',', quotechar = '\"')\n",
    "    spamwriter.writerow(['question_id', 'member_id', 'question'] + cat)\n",
    "    for i in range(len(question_test)):\n",
    "        writestring = [question_test[i], data_dict[question_test[i]]['member_id'], data_dict[question_test[i]]['question']]\n",
    "        writestring += list(y_predict_prob[i])\n",
    "        spamwriter.writerow(writestring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SVM cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "SVM_cv = Pipeline([('cls', SVC()),])\n",
    "parameters = {'cls__kernel': ('linear', 'rbf', 'sigmoid'),\n",
    "              'cls__C': (0.01, 0.1, 1.0, 5, 10),\n",
    "              'cls__gamma': ('auto', 0.1, 1, 10)}\n",
    "gs_cls = GridSearchCV(SVM_cv, param_grid = parameters, cv = 10, n_jobs = mp.cpu_count()-1)\n",
    "gs_cls = gs_cls.fit(X_train.todense(), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Logistic Regression corss validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "LR_cv = Pipeline([('cls', LogisticRegression(max_iter = 200)),])\n",
    "parameters = {'cls__C': (0.1, 0.5, 1, 5, 10),\n",
    "              'cls__solver': ['newton-cg', 'sag', 'lbfgs']}\n",
    "gs_cls = GridSearchCV(LR_cv, param_grid = parameters, cv = 10, n_jobs = mp.cpu_count()-1)\n",
    "gs_cls = gs_cls.fit(X_train.todense(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paras: {'cls__solver': 'newton-cg', 'cls__C': 10}\n"
     ]
    }
   ],
   "source": [
    "print('Best Paras:', gs_cls.best_params_)\n",
    "# y_predict = gs_cls.predict(X_train)\n",
    "y_predict_prob = gs_cls.predict_proba(X_train)\n",
    "\n",
    "cat = [Grammar[item] for item in gs_cls.best_estimator_.classes_]\n",
    "\n",
    "infile = 'predicted/LR_unamb_predict.csv'\n",
    "with open(infile, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter = ',', quotechar = '\"')\n",
    "    spamwriter.writerow(['question_id', 'member_id', 'question'] + cat)\n",
    "    for i in range(len(question_train)):\n",
    "        writestring = [question_train[i], data_dict[question_train[i]]['member_id'], data_dict[question_train[i]]['question']]\n",
    "        writestring += list(y_predict_prob[i])\n",
    "        spamwriter.writerow(writestring)\n",
    "        \n",
    "# print(metrics.classification_report(y_train, y_predict))\n",
    "\n",
    "y_predict_prob = gs_cls.predict_proba(X_test)\n",
    "infile = 'predicted/LR_amb_predict.csv'\n",
    "with open(infile, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter = ',', quotechar = '\"')\n",
    "    spamwriter.writerow(['question_id', 'member_id', 'question'] + cat)\n",
    "    for i in range(len(question_test)):\n",
    "        writestring = [question_test[i], data_dict[question_test[i]]['member_id'], data_dict[question_test[i]]['question']]\n",
    "        writestring += list(y_predict_prob[i])\n",
    "        spamwriter.writerow(writestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pkl files/LR_classifier.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gs_cls.best_estimator_, 'pkl files/LR_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       1.00      0.55      0.71        42\n",
      "         10       0.82      0.77      0.80       106\n",
      "         11       1.00      0.08      0.15        12\n",
      "         12       0.81      0.84      0.83       103\n",
      "          2       0.92      0.56      0.70        39\n",
      "          3       0.86      0.71      0.78        90\n",
      "          4       0.00      0.00      0.00         7\n",
      "          5       0.86      0.76      0.81        93\n",
      "          6       1.00      0.05      0.10        20\n",
      "          7       1.00      0.11      0.20        18\n",
      "          8       0.92      0.24      0.39        49\n",
      "          9       0.56      0.98      0.71       200\n",
      "\n",
      "avg / total       0.79      0.72      0.69       780\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "NB = MultinomialNB(alpha = 0.5)\n",
    "NB.fit(X_train.todense(), y_train)\n",
    "\n",
    "y_predict = NB.predict(X_test.todense())\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "\n",
    "# # dump classifier\n",
    "# joblib.dump(NB, 'NB_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       1.00      0.93      0.96        42\n",
      "         10       0.96      0.94      0.95       106\n",
      "         11       0.92      0.92      0.92        12\n",
      "         12       0.92      0.99      0.95       103\n",
      "          2       1.00      0.87      0.93        39\n",
      "          3       0.93      0.93      0.93        90\n",
      "          4       1.00      0.57      0.73         7\n",
      "          5       0.94      0.98      0.96        93\n",
      "          6       1.00      0.75      0.86        20\n",
      "          7       1.00      0.67      0.80        18\n",
      "          8       1.00      0.84      0.91        49\n",
      "          9       0.88      0.97      0.93       200\n",
      "\n",
      "avg / total       0.94      0.93      0.93       780\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "RF  = RandomForestClassifier(n_jobs=-1, max_features=\"sqrt\", n_estimators=128)\n",
    "RF.fit(X_train.todense(), y_train)\n",
    "y_predicted = RF.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "svc = LinearSVC(C = 1.0, max_iter = 10000)\n",
    "svc = svc.fit(X = X_train.todense(), y = y_train)\n",
    "\n",
    "\n",
    "y_predict = svc.predict(X = X_test)\n",
    "# print(metrics.classification_report(y_test, y_predict))\n",
    "\n",
    "cat = [Grammar[item] for item in svc.classes_]\n",
    "\n",
    "infile = 'predicted/SVM_amb_predict.csv'\n",
    "with open(infile, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter = ',', quotechar = '\"')\n",
    "    spamwriter.writerow(['question_id', 'member_id', 'question'] + cat)\n",
    "    for i in range(len(question_test)):\n",
    "        y_predict_prob = [0]*len(cat)\n",
    "        y_predict_prob[cat.index(Grammar[y_predict[i]])] = 1\n",
    "        writestring = [question_test[i], data_dict[question_test[i]]['member_id'], data_dict[question_test[i]]['question']]\n",
    "        writestring += y_predict_prob\n",
    "        spamwriter.writerow(writestring)\n",
    "\n",
    "y_predict = svc.predict(X = X_train)\n",
    "infile = 'predicted/SVM_unamb_predict.csv'\n",
    "with open(infile, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter = ',', quotechar = '\"')\n",
    "    spamwriter.writerow(['question_id', 'member_id', 'question'] + cat)\n",
    "    for i in range(len(question_train)):\n",
    "        y_predict_prob = [0]*len(cat)\n",
    "        y_predict_prob[cat.index(Grammar[y_predict[i]])] = 1\n",
    "        writestring = [question_train[i], data_dict[question_train[i]]['member_id'], data_dict[question_train[i]]['question']]\n",
    "        writestring += y_predict_prob\n",
    "        spamwriter.writerow(writestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       1.00      0.90      0.95        42\n",
      "         10       0.91      0.97      0.94       106\n",
      "         11       1.00      0.75      0.86        12\n",
      "         12       0.93      0.95      0.94       103\n",
      "          2       0.97      0.95      0.96        39\n",
      "          3       0.91      0.90      0.91        90\n",
      "          4       0.80      0.57      0.67         7\n",
      "          5       0.91      0.90      0.91        93\n",
      "          6       1.00      0.80      0.89        20\n",
      "          7       0.92      0.67      0.77        18\n",
      "          8       0.98      0.88      0.92        49\n",
      "          9       0.89      0.96      0.92       200\n",
      "\n",
      "avg / total       0.92      0.92      0.92       780\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(max_iter = 200, solver = 'newton-cg', C = 10)\n",
    "LR = LR.fit(X = X_train.todense(), y = y_train)\n",
    "y_predict = LR.predict(X = X_test)\n",
    "print(metrics.classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### get fixed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: 3875\n",
      "y train shape: (3875,)\n"
     ]
    }
   ],
   "source": [
    "X_train_text, y_train, X_test_text, y_test, member_train, member_test, question_train, question_test = dh.get_fixed_data()\n",
    "print('X train shape: {}'.format(len(X_train_text)))\n",
    "print('y train shape: {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3875, 10760)\n",
      "(1949, 10760)\n"
     ]
    }
   ],
   "source": [
    "tf = TextFeature(X_train_text, X_test_text)\n",
    "X_train, X_test = tf.get_tfidf()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## write predicted results into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NB = MultinomialNB(alpha = 1.0)\n",
    "NB.fit(X_train.todense(), y_train)\n",
    "y_predict_prob = NB.predict_proba(X_test.todense())\n",
    "cat = [Grammar[item] for item in NB.classes_]\n",
    "out_NB = 'predicted/NB_predicted.csv'\n",
    "with open(out_NB, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter = ',', quotechar = '\"')\n",
    "    spamwriter.writerow(['question_id', 'member_id', 'question'] + cat)\n",
    "    for i in range(len(question_test)):\n",
    "        writestring = [question_test[i], data_dict[question_test[i]]['member_id'], data_dict[question_test[i]]['question']]\n",
    "        writestring += list(y_predict_prob[i])\n",
    "        spamwriter.writerow(writestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "RF  = RandomForestClassifier(n_jobs=-1, max_features=\"sqrt\", n_estimators=128)\n",
    "RF.fit(X_train.todense(), y_train)\n",
    "y_predict_prob = RF.predict_proba(X_test.todense())\n",
    "cat = [Grammar[item] for item in RF.classes_]\n",
    "out_RF = 'predicted/RF_predicted.csv'\n",
    "with open(out_RF, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter = ',', quotechar = '\"')\n",
    "    spamwriter.writerow(['question_id', 'member_id', 'question'] + cat)\n",
    "    for i in range(len(question_test)):\n",
    "        writestring = [question_test[i], data_dict[question_test[i]]['member_id'], data_dict[question_test[i]]['question']]\n",
    "        writestring += list(y_predict_prob[i])\n",
    "        spamwriter.writerow(writestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "SVC = LinearSVC(C=1.0, max_iter=10000)\n",
    "SVC = SVC.fit(X = X_train.todense(), y = y_train)\n",
    "y_predict = SVC.predict(X_test.todense())\n",
    "# cat = [Grammar[item] for item in SVC.classes_]\n",
    "out_SVC = 'predicted/SVC_predicted.csv'\n",
    "with open(out_SVC, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter = ',', quotechar = '\"')\n",
    "    spamwriter.writerow(['question_id', 'member_id', 'question'] + cat)\n",
    "    for i in range(len(question_test)):\n",
    "        writestring = [question_test[i], data_dict[question_test[i]]['member_id'], data_dict[question_test[i]]['question']]\n",
    "        writestring += [Grammar[y_predict[i]]]\n",
    "        spamwriter.writerow(writestring)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
